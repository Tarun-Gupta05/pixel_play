{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90860,"databundleVersionId":10652987,"sourceType":"competition"},{"sourceId":10405689,"sourceType":"datasetVersion","datasetId":6448211}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ngpu_available = torch.cuda.is_available()\nprint(\"GPU Available: \", gpu_available)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import models, transforms\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# device is basically the name of either GPU(if available) or CPU , will be used to move model,input,label for processing\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# saving the paths of all important directories\n\ntrain_dir = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/train\"\ntest_dir = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/test\"\npredicate_matrix_file = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/predicate-matrix-continuous.txt\"\npredicate_matrix_binary= \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/predicate-matrix-binary.txt\"\nclasses_file = \"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/classes.txt\"\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes = [line.strip() for line in open(classes_file).readlines()] # list of class names- BT= index is also read\n\n# classes will read the data as follows\n\n'''classes= '1\\tantelope',\n '2\\tgrizzly+bear',\n '3\\tkiller+whale',   # list\n '4\\tbeaver',\n '5\\tdalmatian',\n '6\\tpersian+cat',\n'''\n\n# to make classes number free and tab/spaces free\nind=0\nimport re\nfor string in classes:\n    str_nodigit = re.sub(r'\\d', '', string)  # removing digits\n    classes[ind]= str_nodigit.replace('\\t', '', 1) # remove tab\n    ind +=1\n\n\n''' creating main dictionary with classes and their sequential index,\nthis index also corresponds to the index of matrix in predicate matrix continuous and binary\n '''\nclass_to_idx= dict(enumerate(classes)) \n\nclasses_for_train=(os.listdir(train_dir)) # list of names of training classes\nprint((classes_for_train))\n \n\nclass_to_idx_train={} # dict of name and idx of training classes\n\n\nfor key , name in class_to_idx.items():\n    if name in classes_for_train:\n        class_to_idx_train[key]=name\n    else:\n        pass\n\n# class_to_idx_train is a part of class_to_idx which only contains training class name and their index\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# loading predicate matrix \npredicate_matrix = np.loadtxt(predicate_matrix_file)\n\n#finding total no of classes and attributes\nnum_classes, num_attributes = predicate_matrix.shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# preprocessing predicate matrix for better model training\n# to remove the -ve values from predicate matrix (total 4 are negative in this matrix out of 4250 )\nfor i in range(50):\n    for j in range(85):\n        if predicate_matrix[i][j] <=0 :\n            predicate_matrix[i][j]= 0   # converting -ve values to 0 since it doesn't make sense\n            \npredicate_matrix= predicate_matrix/100 # converting it in range of [0,1]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# following provides the training image and their traget value of attibutes from predicate_matrix of its class\nclass Train_Dataset(Dataset):\n    def __init__(self, img_main_dir, class_to_idx_train, predicate_matrix, transform=None):\n        self.img_dir = img_main_dir  # main directory of train data\n        self.transform = transform\n        self.images = []  # empty list that stores all images path\n        self.images_class_idx = []  # list to store index of classes the corresponding images belong to\n        self.predicate_matrix = predicate_matrix\n        for idx, class_name in class_to_idx_train.items():  # for loop iterates for each train class\n            class_dir = os.path.join(img_main_dir, class_name) # class directory containing all images of that class\n            for img_name in os.listdir(class_dir): # iterating over all images in the class\n                self.images.append(os.path.join(class_dir, img_name))  # images path are stores\n                self.images_class_idx.append(idx)      # all images are given their respective class index\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        label = self.images_class_idx[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        target = torch.tensor(self.predicate_matrix[label], dtype=torch.float32)\n        return image, target\n#train_dataset = AnimalDataset(train_dir, class_to_idx, predicate_matrix, transform=transform)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model definition\nclass Model_Def(nn.Module):\n    def __init__(self, num_attributes):  # model requires only no. of attributes to be predicted\n        super(AttributePredictor, self).__init__()\n        self.cnn = models.resnet50(pretrained=True)\n        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, num_attributes)\n\n    def forward(self, x):\n        outputs = self.cnn(x)\n        outputs = F.relu(outputs)  # Apply ReLU to the predicted attributes there fore we get only +ve values and in range[0,1]\n        return outputs\n\n\n\n# Initialize model, loss, and optimizer\nmodel = Model_def(num_attributes)\n\nmodel.to(device)\ncriterion = nn.MSELoss()  # Regression loss for attribute prediction\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Image transformations and augmentation\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(p=0.5),          # 50% chance to flip horizontally\n    transforms.RandomVerticalFlip(p=0.5),            # 50% chance to flip vertically\n    transforms.RandomRotation(degrees=25),           # Random rotation within Â±25 degrees\n    transforms.RandomResizedCrop(size=(224, 224),scale=(0.5, 1.0), ratio=(3/4, 4/3)),   # Random crop and resize to 224x224\n                                                                                    # Scale range of crop\n                                                                                   # Aspect ratio range of crop\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n\n\ntrain_dataset = AnimalDataset(train_dir, class_to_idx_train, predicate_matrix, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=25, shuffle=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\n# Training loop\nnum_epochs = 40\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0 # total loss updated after each epoch\n    for images, targets in train_loader:\n        images, targets = images.to(device), targets.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, targets)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\n\n\n#########################################\n\n\ndef zero_shot_inference(model, test_loader, predicate_matrix, class_names):\n    # Set model to evaluation mod\n    model.eval()\n\n   \n    predictions= {} # dictionary that Store image name and final predicted class name\n\n    with torch.no_grad():  # No gradient computation needed during inference\n        for images,names in test_loader:\n            images= images.to(device)  # Move images to GPU if available\n           \n        # Forward pass: get predicted attributes for the images\n            predicted_attributes = model(images) # it is a pytorch tensor of 30 rows since images are 30\n            b=predicted_attributes.cpu().numpy() # b is numpy version of predicted_attributes\n                 \n         # camparing the predicted attribute of the image with predicate matrix row wise using norm and finding the best ma\n            count=0\n            for rows in b:  \n                distances = np.linalg.norm(predicate_matrix - rows, axis=1) \n                # Find the index of the smallest distance (best match) i.e. the index of the predicted class\n                best_match_class_idx = np.argmin(distances)\n                predictions[names[count]]= classes[best_match_class_idx]  # we can map the rows of attribute matrix with the names since they are predicted in sequence when passed with batch of 32 images\n                count +=1\n            \n    return predictions \n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n# for testing \nclass TestDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        \n        \n            #root_dir (str): Path to the directory containing test images.\n            \n        \n        self.root_dir = root_dir\n        self.image_name = sorted(os.listdir(root_dir))  # List of image file names \n        # sorted means to sort alphabetically or numerically the names of images\n        # self.image_paths is a list containing names of images in sorted manner\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_name)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Returns:\n            image (Tensor): Transformed image.\n            image_path (str): Image file name (used for submission).\n        \"\"\"\n        img_path = os.path.join(self.root_dir, self.image_name[idx])\n        image = Image.open(img_path).convert(\"RGB\")  # Open image and convert to RGB\n        \n        if self.transform:\n            image = self.transform(image)  # Apply transformations\n            name= self.image_name[idx] \n        return image, name\n\n        \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define transformations for test images it do not include augmentation just requires simple preprocessing and \ntransform2 = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize images to 224x224\n    transforms.ToTensor(),          # Convert images to PyTorch tensors\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n])\n\n# Create an instance of the custom TestDataset\ntest_dataset = TestDataset(test_dir, transform=transform2)\n\n# Create a DataLoader for the test dataset\ntest_loader = DataLoader(test_dataset, batch_size=30, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Make predictions\npredicted_classes= zero_shot_inference(model, test_loader, predicate_matrix, classes)\n\n# Save predictions to CSV in output of kaggle directory\nimport pandas as pd\n\ndf = pd.DataFrame(list(predicted_classes.items()), columns=['image_id', 'class'])\n\ndf.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}